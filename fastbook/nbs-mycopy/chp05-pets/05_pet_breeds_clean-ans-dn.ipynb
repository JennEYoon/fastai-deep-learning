{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQs3Ka9NxPB7",
    "outputId": "7027e136-ef36-4df2-8462-745bf7ac1c16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 727kB 5.2MB/s \n",
      "\u001b[K     |████████████████████████████████| 51kB 5.1MB/s \n",
      "\u001b[K     |████████████████████████████████| 194kB 8.2MB/s \n",
      "\u001b[K     |████████████████████████████████| 1.2MB 7.5MB/s \n",
      "\u001b[K     |████████████████████████████████| 61kB 6.5MB/s \n",
      "\u001b[?25hMounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "18IWkpPHxPCA"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aX0sbJ1txPCB"
   },
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pk0l7OrNxPCB"
   },
   "source": [
    "## From Dogs and Cats to Pet Breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "NxbQ7WAlxPCB",
    "outputId": "95f6704d-56d8-452d-9c7f-2e704e7ae5cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.PETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### memo    \n",
    "untar_data() downloads data files to Colab Session Storage.  \n",
    "Is gone after instance in close on Colab cloud.  \n",
    "Unix \"tar\" command, compressed and uncompressed data files.  \n",
    "\n",
    "https://www.robots.ox.ac.uk/~vgg/data/pets/  \n",
    "Oxford Univ Geometry Group and Indian Inst I & Tech.  \n",
    "Curated data on dogs and cats breeds.  Some are confusing even for humans to identify.  \n",
    "Manually download to repo on C drive.  Move to Ubuntu and untar (uncompress).  Explore.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZtJYYb0tyBtS"
   },
   "outputs": [],
   "source": [
    "path?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DD9wd2-5ySvJ"
   },
   "source": [
    "Type:        PosixPath\n",
    "String form: /root/.fastai/data/oxford-iiit-pet\n",
    "File:        /usr/lib/python3.6/pathlib.py\n",
    "Docstring:  \n",
    "Path subclass for non-Windows systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGP3ql5W06S-"
   },
   "source": [
    "#### memo: \n",
    "pathlib.py symbolically manipulates drive path.  \n",
    "path.parts() - separates parts out for Winows or Unix OS.  \n",
    "```\n",
    ">>> p = PurePath('/usr/bin/python3')\n",
    ">>> p.parts\n",
    "('/', 'usr', 'bin', 'python3')\n",
    "\n",
    ">>> p = PureWindowsPath('c:/Program Files/PSF')\n",
    ">>> p.parts\n",
    "('c:\\\\', 'Program Files', 'PSF')\n",
    "\n",
    "Usage: \n",
    "from pathlib import Path \n",
    ">>> p = Path('.')  # current directory\n",
    ">>> [x for x in p.iterdir() if x.is_dir()]  # lists all directories in tree. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "y753KA0DxPCC"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XoP0FHY0xPCC",
    "outputId": "7395f928-6e3b-40fa-f31a-4e9a3573e4aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('images'),Path('annotations')]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tUffP4prxPCC",
    "outputId": "85df5946-334d-4592-9ab7-37b02388b020"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#7393) [Path('images/saint_bernard_118.jpg'),Path('images/saint_bernard_31.jpg'),Path('images/Bombay_188.jpg'),Path('images/japanese_chin_82.jpg'),Path('images/Sphynx_90.jpg'),Path('images/Persian_262.jpg'),Path('images/pug_139.jpg'),Path('images/keeshond_120.jpg'),Path('images/keeshond_146.jpg'),Path('images/english_setter_78.jpg')...]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/\"images\").ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "m2HIhYsgzJSF"
   },
   "outputs": [],
   "source": [
    "Path.BASE_PATH?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJAF10GJxPCD"
   },
   "outputs": [],
   "source": [
    "fname = (path/\"images\").ls()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xe-kKbIxPCD"
   },
   "outputs": [],
   "source": [
    "re.findall(r'(.+)_\\d+.jpg$', fname.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSUYf3pzxPCD"
   },
   "outputs": [],
   "source": [
    "pets = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "                 get_items=get_image_files, \n",
    "                 splitter=RandomSplitter(seed=42),\n",
    "                 get_y=using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n",
    "                 item_tfms=Resize(460),\n",
    "                 batch_tfms=aug_transforms(size=224, min_scale=0.75))\n",
    "dls = pets.dataloaders(path/\"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "citCVZ0exPCD"
   },
   "source": [
    "## Presizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQho4xjUxPCE"
   },
   "outputs": [],
   "source": [
    "dblock1 = DataBlock(blocks=(ImageBlock(), CategoryBlock()),\n",
    "                   get_y=parent_label,\n",
    "                   item_tfms=Resize(460))\n",
    "dls1 = dblock1.dataloaders([(Path.cwd()/'images'/'grizzly.jpg')]*100, bs=8)\n",
    "dls1.train.get_idxs = lambda: Inf.ones\n",
    "x,y = dls1.valid.one_batch()\n",
    "_,axs = subplots(1, 2)\n",
    "\n",
    "x1 = TensorImage(x.clone())\n",
    "x1 = x1.affine_coord(sz=224)\n",
    "x1 = x1.rotate(draw=30, p=1.)\n",
    "x1 = x1.zoom(draw=1.2, p=1.)\n",
    "x1 = x1.warp(draw_x=-0.2, draw_y=0.2, p=1.)\n",
    "\n",
    "tfms = setup_aug_tfms([Rotate(draw=30, p=1, size=224), Zoom(draw=1.2, p=1., size=224),\n",
    "                       Warp(draw_x=-0.2, draw_y=0.2, p=1., size=224)])\n",
    "x = Pipeline(tfms)(x)\n",
    "#x.affine_coord(coord_tfm=coord_tfm, sz=size, mode=mode, pad_mode=pad_mode)\n",
    "TensorImage(x[0]).show(ctx=axs[0])\n",
    "TensorImage(x1[0]).show(ctx=axs[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTynYgzDxPCE"
   },
   "source": [
    "### Checking and Debugging a DataBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAUR4qZAxPCE"
   },
   "outputs": [],
   "source": [
    "dls.show_batch(nrows=1, ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwqrYMjOxPCE"
   },
   "outputs": [],
   "source": [
    "pets1 = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "                 get_items=get_image_files, \n",
    "                 splitter=RandomSplitter(seed=42),\n",
    "                 get_y=using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'))\n",
    "pets1.summary(path/\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJeSlex4xPCF"
   },
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fine_tune(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hHUiC-VxPCF"
   },
   "source": [
    "## Cross-Entropy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asoe93UexPCF"
   },
   "source": [
    "### Viewing Activations and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TiCfI_t8xPCF"
   },
   "outputs": [],
   "source": [
    "x,y = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uooamvBUxPCF"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XxOqYdOhxPCF"
   },
   "outputs": [],
   "source": [
    "preds,_ = learn.get_preds(dl=[(x,y)])\n",
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YVJJI4O3xPCG"
   },
   "outputs": [],
   "source": [
    "len(preds[0]),preds[0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9gZtdWMxPCG"
   },
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZwlPw70xPCG"
   },
   "outputs": [],
   "source": [
    "plot_function(torch.sigmoid, min=-4,max=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVkWk3wrxPCG"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "torch.random.manual_seed(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mpglr6IpxPCG"
   },
   "outputs": [],
   "source": [
    "acts = torch.randn((6,2))*2\n",
    "acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfG_riJCxPCH"
   },
   "outputs": [],
   "source": [
    "acts.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uY95bXtsxPCH"
   },
   "outputs": [],
   "source": [
    "(acts[:,0]-acts[:,1]).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GwWuIEExPCH"
   },
   "outputs": [],
   "source": [
    "sm_acts = torch.softmax(acts, dim=1)\n",
    "sm_acts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWvxUpfCxPCH"
   },
   "source": [
    "### Log Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_P4hjcbxPCH"
   },
   "outputs": [],
   "source": [
    "targ = tensor([0,1,0,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "snnrElmHxPCH"
   },
   "outputs": [],
   "source": [
    "sm_acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cctd2LYyxPCI"
   },
   "outputs": [],
   "source": [
    "idx = range(6)\n",
    "sm_acts[idx, targ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDAbBuQSxPCI"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "df = pd.DataFrame(sm_acts, columns=[\"3\",\"7\"])\n",
    "df['targ'] = targ\n",
    "df['idx'] = idx\n",
    "df['loss'] = sm_acts[range(6), targ]\n",
    "t = df.style.hide_index()\n",
    "#To have html code compatible with our script\n",
    "html = t._repr_html_().split('</style>')[1]\n",
    "html = re.sub(r'<table id=\"([^\"]+)\"\\s*>', r'<table >', html)\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HElF1MDExPCI"
   },
   "outputs": [],
   "source": [
    "-sm_acts[idx, targ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pg1VScn8xPCI"
   },
   "outputs": [],
   "source": [
    "F.nll_loss(sm_acts, targ, reduction='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvVP3SQPxPCI"
   },
   "source": [
    "### Taking the Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BtLmA7UwxPCI"
   },
   "outputs": [],
   "source": [
    "plot_function(torch.log, min=0,max=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBDinwyWxPCJ"
   },
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QgOrWOfrxPCJ"
   },
   "outputs": [],
   "source": [
    "loss_func(acts, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSXc_52oxPCJ"
   },
   "outputs": [],
   "source": [
    "F.cross_entropy(acts, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSMcZ89_xPCJ"
   },
   "outputs": [],
   "source": [
    "nn.CrossEntropyLoss(reduction='none')(acts, targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Nxk47mxxPCJ"
   },
   "source": [
    "## Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FF3Av1izxPCJ"
   },
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lgt4ZWeyxPCJ"
   },
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WvkLAqTxPCK"
   },
   "source": [
    "## Improving Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKj7gdfVxPCK"
   },
   "source": [
    "### The Learning Rate Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KVk2ynKXxPCK"
   },
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fine_tune(1, base_lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-zNyHSZxPCK"
   },
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "lr_min,lr_steep = learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDjuW8A7xPCK"
   },
   "outputs": [],
   "source": [
    "print(f\"Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEVEhgOJxPCK"
   },
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fine_tune(2, base_lr=3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncnAIb6hxPCL"
   },
   "source": [
    "### Unfreezing and Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TacNg7HVxPCL"
   },
   "outputs": [],
   "source": [
    "learn.fine_tune??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBp8KHMXxPCL"
   },
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fit_one_cycle(3, 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRy7LLrzxPCL"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B33NL-NOxPCM"
   },
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GK0UPpJTxPCM"
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(6, lr_max=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbOYf9AhxPCM"
   },
   "source": [
    "### Discriminative Learning Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5uCrJsuexPCN"
   },
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fit_one_cycle(3, 3e-3)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(12, lr_max=slice(1e-6,1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZrYALRlxPCN"
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btXEigsWxPCN"
   },
   "source": [
    "### Selecting the Number of Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJMkhOiWxPCN"
   },
   "source": [
    "### Deeper Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkMCv54UxPCN"
   },
   "outputs": [],
   "source": [
    "from fastai.callback.fp16 import *\n",
    "learn = cnn_learner(dls, resnet50, metrics=error_rate).to_fp16()\n",
    "learn.fine_tune(6, freeze_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6nzmMr3xPCN"
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-pueVqhxPCO"
   },
   "source": [
    "## Questionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUqO2a9GxPCO"
   },
   "source": [
    "1. Why do we first resize to a large size on the CPU, and then to a smaller size on the GPU?\n",
    "   * ans: to get squares. PyTorch uses square images.  \n",
    "1. If you are not familiar with regular expressions, find a regular expression tutorial, and some problem sets, and complete them. Have a look on the book's website for suggestions.\n",
    "   * ans: do more exercises.  re.py\n",
    "1. What are the two ways in which data is most commonly provided, for most deep learning datasets?\n",
    "   * ans: individual files where each file is a data item, such as images, with file names perhaps indicate organization.  \n",
    "     Tabular format (csv) where each row is a data item, with possible names associated with image or document files.  \n",
    "     Can also be binary format files, for large dump, such as medical imaging data.  \n",
    "1. Look up the documentation for `L` and try using a few of the new methods is that it adds.\n",
    "   * ans: L is a fastai function, builds on PyTorch nn.convolutions object? \n",
    "1. Look up the documentation for the Python `pathlib` module and try using a few methods of the `Path` class.\n",
    "   * ans: symbolic directory path manipulation. https://docs.python.org/3/library/pathlib.html\n",
    "   \n",
    "1. Give two examples of ways that image transformations can degrade the quality of the data.\n",
    "   * ans: interpolated image can become fuzzy, can have unrelated artifacts (parts of image missing or taken over by other objects)\n",
    "1. What method does fastai provide to view the data in a `DataLoaders`?\n",
    "   * ans: ?\n",
    "1. What method does fastai provide to help you debug a `DataBlock`?\n",
    "   * ans: stepping through, debug. \n",
    "1. Should you hold off on training a model until you have thoroughly cleaned your data? \n",
    "   * ans: No, train as soon as possible.  Use trained model to look for error in data. Exp. unique()\n",
    "1. What are the two pieces that are combined into cross-entropy loss in PyTorch?\n",
    "   * ans: \n",
    "1. What are the two properties of activations that softmax ensures? Why is this important?\n",
    "   * ans: vanishing weights, so later layers will continue to improve learning. \n",
    "   * ? \n",
    "1. When might you want your activations to not have these two properties?\n",
    "1. Calculate the `exp` and `softmax` columns of <<bear_softmax>> yourself (i.e., in a spreadsheet, with a calculator, or in a notebook). \n",
    "   * Later -- do. \n",
    "1. Why can't we use `torch.where` to create a loss function for datasets where our label can have more than two categories?\n",
    "   * ans: We can, but use one-hot encoding to specifiy multiclass (dummy) variables. \n",
    "1. What is the value of log(-2)? Why?\n",
    "   * ans: 2e^(i*pi) in Complex Number space, but undefined in Real Number space. \n",
    "1. What are two good rules of thumb for picking a learning rate from the learning rate finder? \n",
    "   * ans: 1/c ?  Hightest slope decline in accuracy.\n",
    "1. What two steps does the `fine_tune` method do?\n",
    "   * ans: trains the randomly added final layer for one epoch \n",
    "        Unfreeze all layers and train all of them for the N epoches requested. \n",
    "1. In Jupyter Notebook, how do you get the source code for a method or function?\n",
    "   * ans: ??  function??  \n",
    "1. What are discriminative learning rates?\n",
    "   * ans: Use varying rate in layers, depending on user data concordance with trained model data. Usually earier layers train on primative shapes and can be readily transferred to user's data, but later layers learn complex shapes that does not transfer well to user's untrained data. \n",
    "1. How is a Python `slice` object interpreted when passed as a learning rate to fastai?\n",
    "   * ans: start number, end number, interpolate between with geometric growth. learning rate starts low at initial layer, that is already well trained, and gets high towards final layer that has not been trained (our data).\n",
    "1. Why is early stopping a poor choice when using 1cycle training? \n",
    "   * ans: final random layer has not had enough epoches to get accurate.  \n",
    "1. What is the difference between `resnet50` and `resnet101`?  \n",
    "   * ans: more layers. pre-trained models for imagenet database is available for standard number of layers. restnet18 and resnet34 are smaller and good to start with. larger ones are good for trying to improve accuracy. \n",
    "1. What does `to_fp16` do?  \n",
    "   * ans: reduce byte size to floating point 16bit precision, rounds numbers, reduce memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06AnBR1m2H72"
   },
   "source": [
    "#### Regular Expression  \n",
    "re.search()  \n",
    "re.sub  #substitutes  \n",
    "re.finall  \n",
    "re.match  \n",
    "* one or more match  \n",
    "? one or zero match  \n",
    "https://learnbyexample.github.io/python-regex-cheatsheet/   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xk1zUJwbxPCO"
   },
   "source": [
    "### Further Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0ESAZnAxPCP"
   },
   "source": [
    "1. Find the paper by Leslie Smith that introduced the learning rate finder, and read it.\n",
    "1. See if you can improve the accuracy of the classifier in this chapter. What's the best accuracy you can achieve? Look on the forums and the book's website to see what other students have achieved with this dataset, and how they did it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84e2YChxxPCP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "05_pet_breeds_clean.ipynb",
   "provenance": []
  },
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
